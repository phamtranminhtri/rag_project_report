\section{Reranking, RAG-Reasoning, RAG-RL}

\subsection{Reranking in RAG}
\subsection{Towards Agentic RAG with Deep Reasoning: A Survey of RAG Reasoning Systems in LLMs}

Link to paper: \url{https://arxiv.org/abs/2507.09477} \cite{li2025towards}


Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for enhancing large language models (LLMs) by grounding generation in external knowledge sources. However, traditional RAG pipelines primarily focus on surface-level semantic retrieval and often struggle with multi-hop reasoning, noisy contexts, and complex decision-making tasks. The survey by Li et al.\ proposes a comprehensive framework that systematically analyzes how reasoning capabilities can be deeply integrated into RAG systems, moving toward more agentic and intelligent architectures.

The survey categorizes existing approaches into three major paradigms. The first is {Reasoning-Enhanced RAG}, where reasoning is explicitly incorporated to improve retrieval, integration, and generation. At the retrieval stage, techniques such as reasoning-aware query reformulation, retrieval planning, and retriever model enhancement aim to obtain evidence that is more relevant to downstream reasoning tasks. During integration, retrieved documents are assessed, filtered, and fused using reasoning-driven relevance assessment and information synthesis mechanisms. At the generation stage, context-aware and grounded generation methods ensure that the model’s outputs remain faithful to retrieved evidence and follow coherent reasoning paths.

The second paradigm is {RAG-Enhanced Reasoning}, which treats retrieval as a tool to directly support the reasoning process of LLMs. In this setting, models retrieve external knowledge such as structured knowledge bases, web content, tools, or prior experiences to assist in complex reasoning tasks including mathematical problem solving, fact verification, and planning. In-context retrieval of examples and historical interactions further enables LLMs to adapt reasoning strategies dynamically based on retrieved demonstrations or memories.

The third paradigm, {Synergized RAG-Reasoning}, represents the most advanced integration, where retrieval and reasoning are tightly interwoven within an agentic workflow. These systems interleave reasoning steps with retrieval actions using chain-based, tree-based, or graph-based reasoning workflows. Moreover, agent orchestration techniques, including single-agent and multi-agent systems, allow LLMs to autonomously plan, retrieve, reason, and verify information. Such agentic RAG systems exhibit improved robustness, interpretability, and adaptability in complex tasks.




% \begin{table}[]
% \centering
\begin{longtable}{|p{3cm}|p{6.5cm}|p{3.5cm}|}
\hline
\textbf{Category}                            & \textbf{Method summary}                                                                                                                                                                                                                                    & \textbf{Related papers}                                                                                                                              \\ \hline
Reasoning-Aware Query Reformulation (§3.1.1) & Reformulates the original query to better retrieve reasoning-relevant context. This includes query decomposition (breaking complex queries into simpler ones) , reformulation (recasting ambiguous queries) , and expansion (enriching the query via CoT). & e.g., Collab-RAG (Xu et al., 2025b), DynQR (Anonymous, 2025), DeepRetrieval (Jiang et al., 2025)                                                     \\ \hline
Retrieval Strategy and Planning (§3.1.2)     & Covers global retrieval guidance. This involves advance planning to generate a retrieval blueprint before execution or adaptive retrieval methods that predict whether and how to retrieve based on query complexity.                                      & e.g., PAR-RAG (Zhang et al., 2025d), LPKG (Wang et al., 2024b), FIND (Jia et al., 2025)                                                              \\ \hline
Retrieval Model Enhancement (§3.1.3)         & Enhances retrievers with reasoning. This is done by leveraging structured knowledge (like KGs with GNNs or symbolic rules) or integrating explicit reasoning (like CoT) with the query.                                                                    & e.g., GNN-RAG (Mavromatis \& Karypis, 2024), RuleRAG (Chen et al., 2024c)                                                                            \\ \hline
Relevance Assessment \& Filtering (§3.2.1)   & Uses deeper reasoning to assess the relevance of retrieved fragments. This can involve using "assessor experts" to select faithful evidence or models to filter non-entailing passages.                                                                    & e.g., SEER (Zhao et al., 2024c), M-RAG-R (Yoran et al., 2024)                                                                                        \\ \hline
Information Synthesis \& Fusion (§3.2.2)     & Fuses relevant snippets into a coherent evidence set after they are identified. Methods include aggregating sub-question answers or building a reasoning graph to evaluate and aggregate knowledge.                                                        & e.g., BeamAggR (Chu et al., 2024), DualRAG (Cheng et al., 2025), CRP-RAG (Xu et al., 2024)                                                           \\ \hline
Context-Aware Generation (§3.3.1)            & Ensures outputs remain relevant and reduces noise. This includes selective-context utilization (pruning or re-weighting content) and reasoning path generation (building explicit logical chains).                                                         & e.g., Open-RAG (Islam et al., 2024), RARE (Wang et al., 2025d), Self-Reasoning (Xia et al., 2025b)                                                   \\ \hline
Grounded Generation Control (§3.3.2)         & Introduces verification mechanisms to anchor outputs to retrieved evidence. This is done via fact verification , citation generation , and faithful reasoning (ensuring steps adhere to evidence).                                                         & e.g., RARR (Gao et al., 2023a), TRACE (Fang et al., 2024), AlignRAG (Wei et al., 2025b)                                                              \\ \hline
Knowledge Base (§4.1.1)                      & Retrieves from KBs storing arithmetic, commonsense, or logical knowledge. This can include formal lemmas for math , legal precedents , or code snippets.                                                                                                   & e.g., Premise-Retrieval (Tao et al., 2025), ReaRAG (Lee et al., 2025), CBR-RAG (Wiratunga et al., 2024)                                              \\ \hline
Web Retrieval (§4.1.2)                       & Accesses dynamic online content like web pages, news, or social media. It is used for fact-checking by verifying claims step-by-step or for QA by iteratively refining reasoning.                                                                          & e.g., ALR² (Li et al., 2024d), RARE (Tran et al., 2024), Open-RAG (Islam et al., 2024)                                                               \\ \hline
Tool Using (§4.1.3)                          & Leverages external resources like calculators, libraries, or APIs to enhance reasoning interactively. This improves numerical accuracy and computational robustness.                                                                                       & e.g., TATU (Li et al., 2024g), TRICE (Qiao et al., 2024), Re-Invoke (Chen et al., 2024a)                                                             \\ \hline
Prior Experience (§4.2.1)                    & Retrieves past interactions or successful strategies stored in a model's internal memory. This includes leveraging past decisions for planning or recalling conversational histories for adaptive reasoning.                                               & e.g., RAP (Kagaya et al., 2024), JARVIS-1 (Wang et al., 2024f), EM-LLM (Fountas et al., 2024)                                                        \\ \hline
Example or Training Data (§4.2.2)            & Retrieves external examples from demonstrations or training data. This provides relevant exemplars to guide the model in emulating specific reasoning patterns.                                                                                            & e.g., MoD (Wang et al., 2024c), RE4 (Li et al., 2024c), UPRISE (Cheng et al., 2023)                                                                  \\ \hline
Chain-based (§5.1.1)                         & Interleaves retrieval operations between the linear "step-by-step" reasoning of a Chain-of-Thought (CoT) to avoid error propagation. Methods can also add verification or filtering steps.                                                                 & e.g., IRCOT (Trivedi et al., 2023), Rat (Wang et al., 2024g), CoV-RAG (He et al., 2024a), RAFT (Zhang et al., 2024a)                                 \\ \hline
Tree-based (§5.1.2)                          & Explores multiple reasoning pathways. Tree-of-Thought (ToT) methods build a deterministic reasoning tree. Monte Carlo Tree Search (MCTS) methods use probabilistic tree search to dynamically prioritize exploration.                                      & ToT: e.g., RATT (Zhang et al., 2025a), Tree of Clarifications (Kim et al., 2023)  MCTS: e.g., AirRAG (Feng et al., 2025), MCTS-RAG (Hu et al., 2025) \\ \hline
Graph-based (§5.1.3)                         & Walk-on-Graph uses graph learning techniques (like GNNs) to retrieve and reason over graph-structured data. Think-on-Graph integrates graph structures into the LLM's reasoning loop, letting the LLM decide which node to explore next.                   & Walk-on-Graph: e.g., QA-GNN (Yasunaga et al., 2021)  Think-on-Graph: e.g., ToG (Sun et al., 2024b), Graph-CoT (Jin et al., 2024)                     \\ \hline
Single-Agent (§5.2.1)                        & A single agent interweaves retrieval into its reasoning loop. This is achieved via Prompting (e.g., ReAct) , Supervised Fine-Tuning (SFT) , or Reinforcement Learning (RL).                                                                                & Prompting: e.g., ReAct (Yao et al., 2023b)  SFT: e.g., Toolformer (Schick et al., 2023)  RL: e.g., Search-R1 (Jin et al., 2025)                      \\ \hline
Multi-Agent (§5.2.2)                         & Uses multiple agents for collaboration. Decentralized systems use specialized agents that work together. Centralized systems use a hierarchical (e.g., manager-worker) pattern for task decomposition.                                                     & Decentralized: e.g., M-RAG (Wang et al., 2024)  Centralized: e.g., HM-RAG (Liu et al., 2025), Chain of Agents (Zhang et al., 2024c)                  \\ \hline
\end{longtable}
% \end{table}


The survey highlights a clear evolution from static retrieval pipelines toward dynamic, agent-based RAG systems with deep reasoning capabilities. It identifies key challenges such as efficiency, evaluation, and controllability, while outlining future research directions that aim to unify reasoning, retrieval, and agent learning into a coherent framework for next-generation LLM systems.

\subsection{RAG-RL: Advancing Retrieval Augmented Generation via RL and Curriculum Learning}

Link to paper: \url{https://arxiv.org/abs/2503.12759} \cite{huang2025ragrl}