\section{Agent, URAG, LangChain}

\subsection{AI Agent}

An AI agent is a system that leverages an artificial intelligence model to interact with its environment in order to achieve a user-defined objective. Unlike traditional AI systems that produce static outputs, an AI agent integrates reasoning, planning, and action execution to complete tasks in a dynamic and autonomous manner.

\subsubsection{Introduction to AI Agents}

An AI agent operates by receiving a user request, reasoning about the task, selecting appropriate tools, and executing actions to fulfill the objective. This process allows agents to solve multi-step problems that require interaction with external systems and continuous adaptation based on feedback.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{image/agent_workflow.png}
    \caption{High-level AI agent workflow: user request, reasoning, and tool-based action}
    \label{fig:agent_workflow}
\end{figure}

\subsubsection{Core Components of an AI Agent}

AI agents consist of two main components:

\begin{itemize}
    \item \textbf{The Brain (AI Model)}:  
    This component is typically a Large Language Model (LLM) that performs reasoning, understands context, plans future steps, and decides which actions or tools should be used.
    
    \item \textbf{The Body (Capabilities and Tools)}:  
    This component enables the agent to act within its environment. It includes external tools and APIs such as search engines, code execution environments, and databases, as well as memory and observation mechanisms.
\end{itemize}

\subsubsection{Levels of Agent Agency}

AI agents can be categorized according to their level of autonomy, commonly referred to as their \textit{agency level}. As the agency level increases, the agent gains greater control over program execution and decision-making.

\subsubsection{Thought--Action--Observation Cycle}

The behavior of an AI agent follows a continuous loop known as the \textit{Thought--Action--Observation} cycle. In this cycle, the agent first reasons about the problem, then performs an action, and finally observes the result of that action. The observation is used to update the agent’s internal state and guide subsequent reasoning steps.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{image/tao_cycle.png}
    \caption{The Thought--Action--Observation (TAO) cycle in an AI agent}
    \label{fig:tao_cycle}
\end{figure}

This iterative cycle enables agents to adapt their behavior dynamically based on environmental feedback.

\subsubsection{Practical Illustration of the TAO Cycle}

A common example of the Thought--Action--Observation cycle is a task that requires external information, such as retrieving real-time weather data. The agent reasons about the user’s request, calls an appropriate external API, observes the returned data, and then produces a response.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{image/tao_weather_step1.png}
    \caption{Reasoning and action steps using an external weather API}
    \label{fig:tao_weather_1}
\end{figure}

\subsubsection{Observation and Response Generation}

After executing an action, the agent observes the outcome and integrates the feedback into its internal context. Based on this updated information, the agent performs additional reasoning to generate the final response for the user.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{image/tao_weather_step2.png}
    \caption{Observation feedback and final response generation}
    \label{fig:tao_weather_2}
\end{figure}

\subsubsection{Internal Reasoning: Chain-of-Thought and ReAct}

Reasoning is a critical capability of AI agents. Two widely used prompting approaches are:

\begin{itemize}
    \item \textbf{Chain-of-Thought (CoT)}:  
    A technique that encourages the model to reason step-by-step before generating a final answer.
    
    \item \textbf{ReAct (Reasoning and Acting)}:  
    A technique that interleaves reasoning steps with actions, allowing the agent to think, act using tools, observe results, and continue reasoning until the task is completed.
\end{itemize}

\subsubsection{Actions: Enabling Interaction with the Environment}

Actions allow an AI agent to engage with its environment and accomplish tasks. Common categories of actions include information gathering, tool usage, environment interaction, and communication.

\subsubsection{Observation and Adaptation}

After executing an action, the agent observes the outcome and integrates the feedback into its internal context. This enables the agent to update its memory, refine its strategy, and improve performance in future interactions.

\subsection{Unified Hybrid RAG (URAG)}

\subsubsection{Challenges in Conventional RAG}
Despite the success of Retrieval-Augmented Generation (RAG) in grounding LLM responses, several critical challenges remain:
\begin{itemize}
    \item \textbf{Dangerous Hallucinations:} LLMs may still generate plausible-looking but factually incorrect information, which is particularly risky in specialized domains.
    \item \textbf{Accuracy Limitations in Lightweight LLMs:} Smaller, cost-effective models often struggle to maintain high accuracy compared to their larger counterparts.
    \item \textbf{Noise in Retrieval Results:} Irrelevant or noisy documents retrieved from the vector database can distract the model, leading to suboptimal generation.
    \item \textbf{Decoupling of Retrieval and Generation:} A significant disconnect often exists between the retrieval phase and the final generation phase, preventing seamless information flow.
\end{itemize}

\subsubsection{Evolution of Enhancement Strategies}
Various strategies have been proposed to mitigate these issues, though they often come with trade-offs:
\begin{itemize}
    \item \textbf{Retriever Enhancements:} Incorporating structured data, such as Knowledge Graphs, to improve context retrieval.
    \item \textbf{Reflective/Corrective RAG:} Implementing self-correction loops to detect and fix hallucinations by enriching inputs.
    \item \textbf{Speculative RAG:} Utilizing parallel processing to generate multiple draft responses simultaneously.
\end{itemize}
\textbf{Drawbacks:} While effective, these methods significantly increase \textbf{system complexity}, lead to \textbf{longer latency} (processing times), and require \textbf{higher computational resources}.

\subsubsection{The URAG Framework: Tiered Architecture}
The core concept of URAG is inspired by \textbf{Human Advisor Systems}. Just as a human advisor first consults a Frequently Asked Questions (FAQ) list before searching through thick manuals, URAG operates on a tiered retrieval strategy:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{image/urag_idea.png}
    \caption{URAG idea}
    \label{fig:urag_idea}
\end{figure}

\begin{enumerate}
    \item \textbf{Tier 1: Enriched FAQ Database:} This tier utilizes a database that integrates data from various text corpora with existing FAQs. Automated via the \textbf{URAG-F} mechanism, it ensures that common and critical queries receive direct, high-precision responses.
    \item \textbf{Tier 2: Augmented Document Retrieval:} If Tier 1 fails to find a match, the system searches a document corpus enhanced by \textbf{URAG-D}. This mimics traditional RAG but uses optimized prompt templates to guide the LLM.
    \item \textbf{Fallback Mechanism:} In cases where neither tier retrieves sufficient information, the system generates a response directly from the LLM's internal knowledge, accompanied by a \textbf{disclaimer} to manage user expectations regarding potential inaccuracies.
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{image/urag_workflow.png}
    \caption{URAG workflow}
    \label{fig:urag_workflow}
\end{figure}

\subsubsection{URAG Preparation Workflow}
The URAG architecture unifies two preparatory mechanisms to optimize performance. A key component used throughout is \textbf{Chain-of-Thought (CoT) Prompting}, which enhances the reasoning capabilities of the LLM to ensure reliable output.

\paragraph{URAG-D: Document Database Augmentation}
Unlike "Naive RAG" which uses raw document chunks, URAG-D improves retrieval through:
\begin{itemize}
    \item \textbf{Strategic Segmentation:} Dividing documents into coherent, logical chunks.
    \item \textbf{Contextual Rewriting:} Each chunk is rewritten for consistency and contextual relevance. The process extracts the general context of the original document to maintain logical coherence across chunks.
    \item \textbf{Summarization:} A brief summary sentence is prepended to each rewritten chunk to facilitate better matching during retrieval.
\end{itemize}

\paragraph{URAG-F: FAQ Database Enrichment}
The URAG-F mechanism leverages the augmented corpus from URAG-D and the initial FAQ set to:
\begin{itemize}
    \item \textbf{Q-A Pair Generation:} Extract and generate new, high-quality Question-Answer pairs from the processed documents.
    \item \textbf{Linguistic Diversity:} Paraphrase these pairs into multiple variations to ensure the system can handle diverse user phrasing and linguistic styles.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{image/urag_prepare.png}
    \caption{Preparation of URAG}
    \label{fig:urag_prepare}
\end{figure}


\subsection{Introduction to LangChain}

% \subsection{LangChain Framework}

LangChain is a comprehensive framework designed to support the development, deployment, and monitoring of applications powered by Large Language Models (LLMs). It provides modular components and abstractions that simplify the construction of complex LLM-based systems such as Retrieval-Augmented Generation (RAG) pipelines and agentic workflows.

LangChain supports the full lifecycle of an LLM application. During the {development} phase, developers can build applications using LangChain’s core components, including prompt templates, chains, retrievers, vector stores, and integrations with third-party tools and APIs. For more advanced agentic behaviors, LangChain introduces {LangGraph}, which enables the definition of multi-step agents with explicit states, nodes, and control flows. This graph-based design allows agents to reason, invoke tools, and iterate over multiple steps in a structured and controllable manner.

In the {production} phase, LangChain is complemented by {LangSmith}, a platform that provides observability, debugging, and evaluation capabilities. LangSmith allows developers to inspect prompt execution, track intermediate steps, monitor latency and costs, and systematically evaluate model outputs. These features are particularly important for RAG systems, where both retrieval quality and generation accuracy must be continuously assessed.

For {deployment}, LangChain offers the LangGraph Platform, which facilitates the deployment and scaling of agentic workflows. This platform-oriented approach makes LangChain suitable not only for experimentation but also for real-world applications.

Within a RAG architecture, LangChain structures the workflow into two main stages. The first stage is {indexing}, an offline process that involves loading documents, splitting them into chunks, generating embeddings using an embedding model, and storing these embeddings in a vector database. The second stage is {retrieval and generation}, which occurs at runtime: relevant document chunks are retrieved from the vector store based on the user query, combined with the query into a structured prompt, and passed to an LLM to generate a final response.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{image/3_01.png}
    \caption{RAG - Indexing}
    % \label{fig:enter-label}
\end{figure}



LangChain provides a flexible and extensible foundation for building RAG-based and agent-driven applications, enabling developers to integrate LLMs, retrieval systems, and external tools into a unified and production-ready framework.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{image/3_02.png}
    \caption{RAG - Retrieval and Generation}
    % \label{fig:enter-label}
\end{figure}


